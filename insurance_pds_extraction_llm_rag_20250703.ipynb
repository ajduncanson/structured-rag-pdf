{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-augmented generative AI pipeline\n",
    "### to provide structured answeres to questions about documents\n",
    "\n",
    "specifically, Insurance product disclosure statements\n",
    "\n",
    "Author: AJ Duncanson, heavily borrowing from Thu Vu, see readme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --quiet langchain langchain-community langchain-openai chromadb langchain_chroma\n",
    "!pip3 install --upgrade --quiet pypdf pandas streamlit python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Langchain modules\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Other modules and packages\n",
    "import os\n",
    "import tempfile\n",
    "import streamlit as st  \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our LLM and our set of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "# llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define PDS set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDS_folder = \"/Users/aj.duncanson/projects/structured-rag-pdf/pds/\"\n",
    "results_folder = \"/Users/aj.duncanson/projects/structured-rag-pdf/results/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provider = \"QBE\"\n",
    "# PDSs = [\n",
    "#     \"QM8505-1123 QBE Comprehensive Car Insurance PDS (web).pdf\"\n",
    "# ]\n",
    "# product_name = \"Comprehensive Car Insurance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provider = \"Rollin\"\n",
    "# PDSs = [\n",
    "#     \"1747889291-rollin-car-insurance-pds-v4-29-apr-2025.pdf\"\n",
    "# ]\n",
    "# product_name = \"Comprehensive Car Insurance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provider = \"Youi\"\n",
    "# PDSs = [\n",
    "#     \"youi car-pds 20250702.pdf\"\n",
    "# ]\n",
    "# product_name = \"Comprehensive Car Insurance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = \"Budget Direct\"\n",
    "PDSs = [\n",
    "    \"Budget Direct car PDS A.pdf\",\n",
    "    \"Budget Direct Car Gold PDS B.pdf\"\n",
    "]\n",
    "product_name = \"Comprehensive Gold Car Insurance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define question set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_file = \"car_insurance_questions.csv\"\n",
    "question_column = 'questions 20250702-06'\n",
    "\n",
    "questions = pd.read_csv(PDS_folder+question_file)\n",
    "data_points = questions[\"data_point\"]\n",
    "questions = questions[question_column]\n",
    "\n",
    "questions = [q + \", if I have the \" + product_name + \" product.\" for q in questions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process PDF document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PDF document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pages = []\n",
    "for p in PDSs:\n",
    "    loader = PyPDFLoader(PDS_folder + p)\n",
    "    these_pages = loader.load()\n",
    "    pages.extend(these_pages)\n",
    "\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500,\n",
    "                                            chunk_overlap=200,\n",
    "                                            length_function=len,\n",
    "                                            separators=[\"\\n\\n\", \"\\n\", \" \"])\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_function():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\", openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding_function = get_embedding_function()\n",
    "test_vector = embedding_function.embed_query(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.evaluation import load_evaluator\n",
    "\n",
    "# evaluator = load_evaluator(evaluator=\"embedding_distance\", \n",
    "#                             embeddings=embedding_function)\n",
    "\n",
    "# evaluator.evaluate_strings(prediction=\"Amsterdam\", reference=\"coffeeshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.evaluate_strings(prediction=\"Paris\", reference=\"coffeeshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function\n",
    "                       #, vectorstore_path\n",
    "                       ):\n",
    "\n",
    "    # Create a list of unique ids for each document based on the content\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    # Ensure that only unique docs with unique ids are kept\n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    # Create a new Chroma database from the documents\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        #persist_directory = vectorstore_path\n",
    "                                        )\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "\n",
    "# # Ensure that only unique docs with unique ids are kept\n",
    "# unique_ids = set()\n",
    "# unique_chunks = []\n",
    "\n",
    "# unique_chunks = [] \n",
    "# for chunk, id in zip(chunks, ids):     \n",
    "#     if id not in unique_ids:       \n",
    "#         unique_ids.add(id)\n",
    "#         unique_chunks.append(chunk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = create_vectorstore(chunks=chunks, \n",
    "                                 embedding_function=embedding_function, \n",
    "                                 #vectorstore_path=\"vectorstore_chroma\"\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query for relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorstore\n",
    "#vectorstore = Chroma(persist_directory=\"vectorstore_chroma\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever \n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "# relevant_chunks = retriever.invoke(\"Who underwrites this policy\")\n",
    "# relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. \n",
    "Your task is to answer the question about specific details of the insurance policy described in the retrieved context.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create prompt\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate context text\n",
    "#context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "# prompt = prompt_template.format(context=context_text, \n",
    "#                                 question=\"Who underwrites this policy?\")\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Langchain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rag_chain = (\n",
    "#             {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "#             | prompt_template\n",
    "#             | llm\n",
    "#         )\n",
    "# rag_chain.invoke(\"What's the name of the insurance product?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate structured responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still exploring the structure that's most useful for our needs, and also using very early draft prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AnswerWithSources(BaseModel):\n",
    "#     \"\"\"An answer to the question, with sources and reasoning.\"\"\"\n",
    "#     answer: str = Field(description=\"Answer to question\")\n",
    "#     sources: str = Field(description=\"Full direct text chunk from the context used to answer the question\")\n",
    "#     reasoning: str = Field(description=\"Explain the reasoning of the answer based on the sources\")\n",
    "\n",
    "# class ExtractedInfoWithReasoning(BaseModel):\n",
    "#     \"\"\"Extracted information about the cover item\"\"\"\n",
    "#     summary_details: AnswerWithSources\n",
    "#     dollar_limit: AnswerWithSources\n",
    "#     conditions: AnswerWithSources\n",
    "#     exclusions: AnswerWithSources\n",
    "\n",
    "# class JustInfo(BaseModel):\n",
    "#     \"\"\"Extracted information about the cover item\"\"\"\n",
    "#     summary: str = Field(description=\"Answer to question\")\n",
    "#     dollar_limit: str = Field(description=\"Answer to question\")\n",
    "#     conditions: str = Field(description=\"Answer to question\")\n",
    "#     exclusions: str = Field(description=\"Answer to question\")\n",
    "\n",
    "class ExtractedInfo(BaseModel):\n",
    "    \"\"\"Extracted information about the cover item\"\"\"\n",
    "    this_item_of_cover_is_included_as_standard: bool = Field(\"Cover is included as standard, not optional\")\n",
    "    this_item_of_cover_is_optional: bool = Field(\"Cover is optional, not included as standard\")\n",
    "    this_item_is_not_covered_at_all: bool = Field(\"This cover is not provided at all\")\n",
    "\n",
    "    #is_this_part_of_the_standard_cover_or_an_optional_cover_or_not_covered:  str = Field(description=\"Standard Cover or Optional Cover or Not Covered\")\n",
    "    summary: str = Field(description=\"Summary of answer to question, including all relevant numerical limits\")\n",
    "    #summary_2: str = Field(description=\"A concise summary of the cover provided\")\n",
    "    list_of_numerical_limits_related_to_this_item_of_cover: str = Field(\"List the numerical limits that apply to this specific item of cover including dollar limits, limits on the number of days the benefit can be paid, and limits to the number of years or number of kilometers used in determining whether this cover applies\") \n",
    "    #numerical_limits_to_the_dollars_or_distance_or_timeframe_2: str = Field(\"Answer to question\") \n",
    "    #dollar_limit: str = Field(description=\"Answer to question\")\n",
    "    #other_limits_to_cover: str = Field(description=\"What other limits apply to the cover, other than dollar amounts?\")\n",
    "    #other_limits_to_cover_2: str = Field(description=\"What distance, time period or other limits apply to the cover, other than dollar amounts?\")\n",
    "    conditions: str = Field(description=\"Answer to question\")\n",
    "    exclusions: str = Field(description=\"Answer to question\")\n",
    "    sources: str = Field(description=\"Full direct text chunk from the context used to answer the question\")\n",
    "    reasoning: str = Field(description=\"Explain the reasoning of the answer based on the sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm.with_structured_output(ExtractedInfo, strict=True)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get structured responses and compile into a result format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the structured responses for each question in the array\n",
    "\n",
    "structured_responses = [rag_chain.invoke(q).model_dump() for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in a df \n",
    "\n",
    "df = pd.DataFrame(structured_responses)\n",
    "\n",
    "df.insert(0, \"provider\", provider)\n",
    "df.insert(1, \"PDS\", \", \".join(PDSs))\n",
    "df.insert(2, \"data_point\", data_points)\n",
    "df.insert(3, \"question\", questions)\n",
    "df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "df.to_csv(results_folder+\"pds_output_\"+provider+\"_\"+timestamp+\".csv\", index=False)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
